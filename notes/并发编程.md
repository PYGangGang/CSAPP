# 并发编程

**什么是并发**

---

还记得刚毕业找工作的时候（也几乎就是刚开始自学计算机的时候），关于并发和并行，我背了不少的八股文；什么并行是一种特殊的并发，并行就是多核，广义并发是 CPU 的时分复用之类的。虽然都对，但是这里还是写一下我对《CS: APP》里概念的理解，加深印象：

> 并发（concurrency）是指多个逻辑控制流的开始到结束，在时间上存在交集的现象
> 
> 并行（parallel）是指在并发的前提下，多个逻辑控制流，在时间上存在重叠的现象（在多个计算单元上）。

这些只是概念理解，接下来是真正实现并发的几种常见方式：

* 多进程
* I / O 复用
* 多线程

我们用并发编程的最常见场景，服务器来讲解。当然，也有纯粹的 SIMD 指令、GPU 并行计算等，这咱就不讨论了。

**基于进程的并发编程**

---

基于进程的并发实际上就是将调度的任务彻底交给了内核，使用 fork, exec, waitpid 等系统调用，创建新的进程执行一些程序。这里带来了很明显的优势，父子进程共享文件描述符、各进程间完全不会互相影响，我们不用太关心调度。

**基于多进程的并发服务器**

我们在主进程用一个 passive socket 来监听请求，每当请求到来，在主进程里建立连接后，将连接描述符“交给”子进程，由子进程负责响应。注意事项标注在代码中：

```cpp
#include "csapp.h" // 太多头文件和自定义包装函数了，我就不自己打了

void echo(int connfd); // 往 connfd 里写回显的函数，之前的笔记里有实现

void sigchld_handler(int sig) {
    while (waitpid(-1, 0, WNOHANG) > 0) {
        // DONOTHING
        // 注意这里用了 -1，因为信号不会排队，我们每次收到 SIGCHLD 都要尽可能多地回收
    }
    return;
}

int main(int argc, char **argv) {
    int listenfd, connfd;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;

    // 检查参数
    if (argc != 2) {
        fprintf(stderr, "usage: %s <port>\n", argv[0]);
        exit(0);
    }

    // 必须显式回收子进程；
    // 虽然说主进程结束过后，子进程会被自动回收
    // 但是对于这样一个服务器的场景，我们不知道什么时候主进程会结束，很容易 OOM
    Signal(SIGCHLD, sigchld_handle);
    listenfd = Open_listenfd(argv[1]);

    // here we go =)
    while(1) {
        clientlen = sizeof(struct sockaddr_storage);
        connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen);
        if (Fork() == 0) {
            Close(listenfd); // 子进程用不了监听描述符了
            echo(connfd);
            Close(connfd); // 此时父子进程的文件描述符表都有一项指向这个 socket
            exit(0);
        }
        Close(connfd); // 子进程用完了 connfd，父进程也必须关闭，不然仍有引用不会删除
    }
}
```

多进程的缺点也非常明显，进程不共享用户地址空间，必须使用进程间通信（IPC, Inter-Process Communication)；希望之后有时间来补充一下常见的方法：信号、socket、管道、命名管道、FIFO、系统 V 共享内存、系统 V 信号量。

**基于 I/O 多路复用的并发编程**

---

《CS: APP》直接就用一个服务器例子开始讲了，我一开始看得比较懵，让我们先解释一下概念。I/O 多路复用（I/O multiplexing）是指一种可以让内核通知进程，某个设备有数据可读的机制，Linux 上 select, poll, epoll 都可以实现。此处用 select 的读操作举例。

首先考虑之前的 echo 服务器模型，我们给它加上能够响应本地命令的功能，那么我们实际上需要处理两个 I/O 事件：

* listenfd 是否有新的建立连接请求
* stdin 是否有新的输入

显然，我们可以从 accept 开始一直阻塞到完成响应，但是这个时候我们就完全响应不了命令行了；而使用 I/O 多路复用我们就可以这样实现：select 函数会阻塞在等待一个 connfd 集合有新的请求到来，一旦有一个或多个 fd 可以读了，才会返回到当前进程。select 的形式如下：

```cpp
#include <sys/select.h>

int select(int n, fd_set *fdset, NULL, NULL, NULL);

FD_ZERO(fd_set *fdset); // 清空 fdset 里的所有位
FD_CLR(int fd, fd_set *fdset); // 清空 fdset 里 fd 对应的位
FD_SET(int fd, fd_set *fdset); // 在 fdset 里加入 fd
FD_ISSET(int fd, fd_set *fdset); // 在 fdset 里的 fd 可读了吗？
```

在准备好 fdset （一个标记 fd 的位向量，用以上四个宏操作）后，select 会一直阻塞直到这个集合里至少有一个描述符可读；select 会修改 fdset 指向的 fd_set，将其填充为可读 fd 的集合（所以得注意保存原始描述符集合）。很简单地，我们就可以写出以下 echo 服务器代码：

```cpp
#include "csapp.h"
void echo(int connfd);
void command(void);

int main(int argc, char **argv) 
{
    int listenfd, connfd;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;
    fd_set read_set, ready_set;

    if (argc != 2) {
	fprintf(stderr, "usage: %s <port>\n", argv[0]);
	exit(0);
    }
    listenfd = Open_listenfd(argv[1]);

    FD_ZERO(&read_set);              // 先准备一个空地集合
    FD_SET(STDIN_FILENO, &read_set); // 将 stdin 填进去
    FD_SET(listenfd, &read_set);     // 将 listenfd 填进去

    while (1) {
	ready_set = read_set;
	Select(listenfd+1, &ready_set, NULL, NULL, NULL); // 阻塞直到有 IO
	if (FD_ISSET(STDIN_FILENO, &ready_set)) // 如果是 stdin 的，我们调用 command 执行指令
	    command();
	if (FD_ISSET(listenfd, &ready_set)) { // 如果是 listenfd 的，我们建立新的 connfd 并响应
            clientlen = sizeof(struct sockaddr_storage); 
	    connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen);
	    echo(connfd); /* Echo client input until EOF */
	    Close(connfd);
	}
    }
}

void command(void) {
    char buf[MAXLINE];
    if (!Fgets(buf, MAXLINE, stdin))
	exit(0); /* EOF */
    printf("%s", buf); // 假设就打印一下命令
}
```

这里有一个很明显的问题，如果 accept 了某个连接，那会一直响应到客户端结束连接，这之间也是无法响应任何东西的，但是好歹解决了我们听多个 IO 的希望。

**基于 I/O 多路复用的并发事件驱动服务器**

I/O 多路复用可以用作 event-driven 的基础。我们将逻辑控制流抽象为一个有限状态机，当一个输入事件（此处为 I/O）的发生，就推动这个状态机变化。那么我们可以将 echo 服务器（不带命令行）抽象为以下状态机：

```cpp
输入事件：“描述符 i 准备好可读了”           转移：“从描述符 i 读一个文本行”
                         ____________________   
                        |                    |
                        |                    \/
                    状态：“等待描述符 i 准备好可读”
```

详细的代码看：[echoservers.c](../codes/concurrent_servers/echoserver.c)，此处讲一下思想：

* 定义一个数据结构 pool 来装所有的需要监听的 fd
  * 很明显，此处我们需要监听 listenfd 以建立新的连接、监听 connfd 以响应请求
* 首先用 init_pool() 初始化 pool，将唯一的 listenfd 放进去
* 进入经典服务器死循环，开头调用 select 阻塞等待（此时只有一个 listenfd）
  * 当 select 返回时，我们首先判断 listenfd 上有没有新连接请求
    * 若有，则用 add_client() 在 pool 里创建并加入一个 connfd
  * 其次用 check_clients() 检查 pool 里的所有 connfd 是否有新请求来
    * 若有，则 echo() 一行
    * 若读 connfd EOF 了，则 close connfd 并从 pool 里把它删了

基于 I/O 多路复用的并发编程还有很多拓展，希望能够补充：reactor, proactor 模型。

**基于线程的并发编程**

---

**线程的基本概念**

多进程有内核隐式地调度，进程间不共享用户空间；I/O 多路复用由程序员显式地调度，逻辑流之间可以共享用户空间；线程则是综合了两者，它由内核调度、线程间可以共享用户空间。每个线程包含自己的上下文，其中有线程 ID 、栈、栈指针、程序计数器、通用目的寄存器、条件码。线程的两个小特性如下：

* 线程的上下文切换比进程的快很多：主要区别在于虚拟地址空间的切换与否；因为线程都共享一个虚拟地址空间，所以不需要切换；而进程都有自己的虚拟地址空间，所以此处就需要一些内核操作去切换（我理解为至少需要换页表）；这里貌似也不是很费劲，因为也就把页表指针放到 CR3 就行了，但是真正慢的是在 cache 的缺失；当虚拟地址空间切换，很多 cache 会失效，此处就有很大的拷贝时间了；参考：[pthread context switch vs. process context switch](https://stackoverflow.com/questions/5440128/thread-context-switch-vs-process-context-switch)
* 线程不存在上下级关系，主线程也如是：同一个进程中的所有的线程组成一个对等线程池；主线程只是说它是第一个运行的线程；每个线程都可以“杀死”其他线程

**Posix Thread（Pthreads）**

直接用 C 里面 pthread 的函数简单讲解

* 线程例程（thread routine）

线程的代码和本地数据封装在一个 thread routine 中。用通用指针作为输入和返回（多参数、多返回使用 struct）：

```cpp
void *thread(void *vargp) {
    printf("this is my thread\n");
    return NULL;
}
```

* 创建线程

某线程通过调用 pthread_create() 来创建其他线程：

```cpp
#include <pthread.h>
typedef void *(func)(void *vargp);

int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg);
```

attr 参数可以改变线程的默认属性，此处不细讲；创建成功之后，tid 会返回新创建线程的 id；在新创建的线程中，可以使用 pthread_slef() 来获取自己的 id：

```cpp
pthread_t pthread_slef(void);
```

* 终止线程
  * 当顶层的 thread routine 返回时，线程会隐式地结束
  * 调用 pthread_exit() 线程会显式地结束
    * 主线程调用时，会等到其他所有对等线程结束，然后再终止主线程和整个进程

```cpp
void pthread_exit(void *thread_return);
```

另外的：某线程调用 exit() 时，整个进程都会终止；可以使用 pthread_cancel() 来结束其他进程：

```cpp
int pthread_cancel(pthread_t tid);
```

* 回收已终止线程的资源

用 pthread_join() 阻塞当前线程，直到指定线程终止，将指定 thread routine 的返回的通用指针，赋值为 thread_return 指向的位置。

```cpp
int pthread_join(pthread_t tid, void **thread_return);
```

* 分离线程

任何时刻，一个线程都处在可结合的（joinable）或分离的（detached）状态中。 joinable 线程能够被其他线程回收或杀死，而在被其他线程回收（join）之前，它的资源是不释放的；detached 线程不能被其他线程回收或杀死，在 thread routine 结束后，其资源会立刻自动释放。

默认情况下创建的线程都是 joinable 的，我们可以用 pthread_detach 来分离它：

```cpp
int pthread_detach(pthread_t tid); // 结合 pthread_slef() 来分离自己

pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);
pthread_create(&pid, &attr, threadRoutine, NULL); // 用这种方式创建一个 detached 线程
```

* 初始化线程

pthread_once 第一次在某线程中被调用时，会执行一个没有参数也没有返回的 init_routine；后续的 pthread_once 调用将没有任何效果；这可以用来初始化某些全局变量。

```cpp
pthread_once_t once_control = PTHREAD_ONCE_INIT;
int pthread_once(pthread_once_t *once_control, void (*init_routine)(void));
```

**基于线程的简单 echo 服务器**

基于线程写起来就显得简单了许多，但是我们要特别注意“竞争”。

```cpp
#include "csapp.h"

void echo(int connfd);
void *thread(void *vargp);

int main(int argc, char **argv) 
{
    int listenfd, *connfdp;
    socklen_t clientlen;
    struct sockaddr_storage clientaddr;
    pthread_t tid; 

    if (argc != 2) {
	fprintf(stderr, "usage: %s <port>\n", argv[0]);
	exit(0);
    }
    listenfd = Open_listenfd(argv[1]);

    while (1) {
    clientlen=sizeof(struct sockaddr_storage);
	connfdp = Malloc(sizeof(int)); 
	*connfdp = Accept(listenfd, (SA *) &clientaddr, &clientlen);
	Pthread_create(&tid, NULL, thread, connfdp);
    /**
    这里如果这样写会发生什么呢？
    connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen);
    Pthread_create(&tid, NULL, thread, &connfd)
    */
    }
}

/* Thread routine */
void *thread(void *vargp) 
{  
    int connfd = *((int *)vargp);
    Pthread_detach(pthread_self()); // 因为我们不会主动回收，所以每个线程都得自己 detach
    Free(vargp);                    // connfd 已经进到线程栈了，赶紧把内存释放了
    echo(connfd);
    Close(connfd);
    return NULL;
}
```

**线程中的共享变量**

---

* 线程内存模型

如前文所说，每个线程有自己的上下文，并和其他线程一起共享进程的虚拟内存空间。从实际上，线程间无法共享在寄存器里的值，但是内存里（上下文或线程的本地数据）的内容是不设防的，可以互相访问的。

* 将变量映射到内存：和函数的变量 scope 类似
  * 全局变量：定义在函数之外的变量。进程的虚拟内存中的读/写区域包含了全局变量的唯一实例，每个线程都可以引用。
  * 本地自动变量：定义在 thread routine 中的普通变量。只对当前线程可见。
  * 本地静态变量：定义在 thread routine 中的带 static 关键字的变量。和全局变量类似，也只有一个实例，只会在第一次声明并赋值的时候初始化一次，之后所有的对等线程都可以访问。

*** static 和 global 变量的区别在于它们的链接方式。global 变量是全局可见且唯一的（包括不同 source file）；而定义在函数体内的 static 变量只在当前 source file 里全局可见，不同的source file 里可以有重名。

**信号量（semaphore）**

---

引入共享变量过后，**竞争**就是一个老生常谈的问题了。一个典型的场景就是，我们不加保护地让多个线程对一个共享变量做累加操作，最后的结果往往不确定且不如预期。当我们用汇编代码来看，涉及到共享变量的累加的部分分为以下三步：

* 加载共享变量到累加寄存器
* 对该寄存器内的值进行累加操作
* 将累加寄存器中的值更新到共享变量

很明显，不同的线程并不能保证它们之间执行这三步的顺序。可能线程 1 读变量到寄存器后，内核调度到线程 2 也执行读变量到寄存器，那最后两个线程执行完累加过后，只加了一次。《CS: APP》p701 讲了一种描述并发线程执行的模型化：进度图（progress graph），其中将操作共享变量的区域称为临界区，而我们必须保证**临界区的互斥访问**。我们可以用信号量来保证。

**信号量基本概念**

信号量是一种只支持两种特殊的原子操作的特殊变量。操作称为 P & V：

* P(s)：如果 s 非 0，则将 s 减 1 立即返回；若 s 为 0，则挂起该线程，直到 s 变为非 0；线程被 V 操作重启后，P 操作会将 s 减 1 然后返回。
* V(s)：将 s 加 1；V 操作会重启一个被 P 挂起的线程。

Posix 标准中的信号量函数：

```cpp
#include <semaphore.h>

int sem_init(sem_t *sem, 0, unsigned int value); // 初始化信号量 sem 为 value
int sem_wait(sem_t *s); // P 操作
int sem_post(sem_t *s); // V 操作
```

**信号量实现互斥**

我们将一个信号量（初始为 1）和一个（或一组）共享变量关联起来，在操作这个共享变量时，用 P 和 V 操作将其包围。这种称为*二元信号量（binary semaphore）*或*互斥锁（mutex）*，P 就称为*加锁*，V 就称为*解锁*。

mutex 只有 0 或 1 两种状态；当某线程试图访问这个共享变量时，mutex 为 1 则可以访问，mutex 为 0 则表示有另一个线程执行了加锁，还没有解锁，那么 P 操作将当前线程挂起，直到其他线程解锁。

一个用互斥锁实现的累加：[mutex.cpp](codes/mutex.cpp)

**信号量调度共享变量**

信号量也可以用来“通知”另一个线程，某个东西已经“ok”了，我们用两个设计模式来讲一下。

* **生产者 - 消费者问题**

生产者线程和消费者线程共享一个缓冲区；生产者生成新的项目放入缓冲区中，而消费者从缓冲区中取出项目使用。可以看到，这里需要共享的“东西”还不少：

* 插入和取出都要更新共享变量，所以此处需要互斥访问
* 插入需要确保缓冲区中有空槽位
* 取出需要确保缓冲区中有项目

这个比较有意思，我们来看下所有的代码：

首先用一个 sbuf_t 结构来定义一个缓冲区：

```cpp
typedef struct {
    int *buf;       // 缓冲区数组
    int n;          // 缓冲区的大小
    int front;      // 第一个 item 的下标
    int rear;       // 最后一个 item 的下标
    sem_t mutex;    // 对 buf 访问提供互斥访问的信号量
    sem_t slots;    // 对可用 slot 进行计数的信号量
    sem_t items;    // 对可用 item 进行计数的信号量
} sbuf_t
```

那么对于这个缓冲区，我们可以的操作有：初始化、释放、插入、取出；它们的注意事项如下：

* 初始化：我们需要为缓冲区数组分配内存和初始化各个信号量的状态；mutex 明显是一个互斥锁，并且初始肯定是可用状态，那么初始值为 1；slots 是一个计数器，当它为 0 时代表没有 slot 了，线程会挂起等待取出操作来腾出 slot，一开始都可用所以初始化为 n；items 是一个计数器，当它为 0 时代表没有可用 item 了，线程会挂起等插入操作来增加 item，一开始必然没有可用的所以初始化为 0：

```cpp
void sbuf_init(sbuf_t *sp, int n)
{
    sp->buf = Calloc(n, sizeof(int)); 
    sp->n = n;                       /* Buffer holds max of n items */
    sp->front = sp->rear = 0;        /* Empty buffer iff front == rear */
    Sem_init(&sp->mutex, 0, 1);      /* Binary semaphore for locking */
    Sem_init(&sp->slots, 0, n);      /* Initially, buf has n empty slots */
    Sem_init(&sp->items, 0, 0);      /* Initially, buf has zero data items */
}
```

* 释放：buf 是一个动态分配的内存，我们必须释放：

```cpp
void sbuf_deinit(sbuf_t *sp)
{
    Free(sp->buf);
}
```

* 插入：有了初始化时候的讲解，插入操作自然首先需要对 slots 进行 P 操作，以确保现在有空位；返回之后代表有空位了，我们自然要更新 sbuf_t 里的数据，所以再加上 mutex；完事儿之后呢，我们需要对 items 进行 V 操作，代表加了一个 item：

```cpp
void sbuf_insert(sbuf_t *sp, int item)
{
    P(&sp->slots);                          /* Wait for available slot */
    P(&sp->mutex);                          /* Lock the buffer */
    sp->buf[(++sp->rear)%(sp->n)] = item;   /* Insert the item */
    V(&sp->mutex);                          /* Unlock the buffer */
    V(&sp->items);                          /* Announce available item */
}
```

* 取出：和插入类似，此处我们减少 items 计数，增加 slots 计数：

```cpp
int sbuf_remove(sbuf_t *sp)
{
    int item;
    P(&sp->items);                          /* Wait for available item */
    P(&sp->mutex);                          /* Lock the buffer */
    item = sp->buf[(++sp->front)%(sp->n)];  /* Remove the item */
    V(&sp->mutex);                          /* Unlock the buffer */
    V(&sp->slots);                          /* Announce available slot */
    return item;
}
```

* **读者 - 写者问题**

该问题是对互斥问题的一个概括。当一组线程访问某个共享变量，一些线程只读（读者），一些线程只写（写者）；可以想见，写者需要对共享对象的独占访问（写肯定是读 + 写，必然不是原子操作），而读者则不需要。我们再将其根据读写的优先级做个变种：

* 读者优先：除非对象的使用权已经交给了一个写者，读者永远不等；读者不会因为有写者等待而等待
* 写者优先：写者能写就尽快让他写，所以后来的读者会排在先到的写者后面

我们实现一个读者优先，非常有意思：

```cpp
int readcnt; // 当前在读的读者计数，初始值为 0
sem_t mutex; // 对 readcnt 的互斥锁
sem_t w; // 对写行为（共享变量）的互斥锁

void read(void) {
    while(1) {
        P(&mutex);
        ++readcnt;
        if (readcnt == 1) // 第一个读者到来
            P(&w); // 代表“读大爷”来了，写者等着吧
        V(&mutex);

        // read, read, read

        P(&mutex);
        --readcnt;
        if (readcnt == 0) // 最后一个读者走了
            V(&w); // “读大爷”已走，勿扰
        V(&mutex);
    }
}

void write(void) {
    while (1) {
        P(&w); // 让写吗？

        // write, write, write

        V(&w);
    }
}
```

从以上这个简单的代码可以想见，当一个读者给 w 加锁了，后续读者一直来的话，写者就无限期阻塞了，我们称为**饥饿（starvation）**；另外给读者的优先级其实也不高，有机会产生读者的饥饿：

* 第一个读者进了 read() 开头的 mutex 锁，但是在拿到 w 锁之前，写者先拿到了 w 锁；此时无数读者和写者涌入；读者因为进不去 mutex，所以都无法去拿 w；写者则都对 w 进行了 P 操作，排上了队；当第一个写者释放 w 的时候，它从排队线程中随便抽一个，很难抽到只有一个的读者线程。
* 一波读者完事儿之后，它们释放了 w 锁，但是还没来得及释放 mutex，写者就拿到 w 锁开始搞了；明显，此时其他读者完全进不来；所以写者只会唤醒其他写者；但是控制权交给最开始的读者线程，解了 mutex 就好了。

**信号量的简单小结**：通过这几个例子，目前看来信号量就是个计数器；互斥锁场景中，值为 0 代表被占用了，其他人等着吧，值为 1 就代表可用；初始化为 1 后，我们总是从 -1 进去 +1 出来，所以信号量也就在 0 1 之间跳，达到了一个互斥的效果；调度场景中，信号量被用来对特定操作计数，有加有减的过程中，就是不能等于 0，等于 0 了其他人就等着吧；

**一个例子：基于预线程化的 echo 服务器**

在上一个*基于线程的简单 echo 服务器*里，每来一个请求，我们就创建一个线程来响应它，当请求多了过后呢，线程的调度开销会上涨（后续讨论多核并行的时候我们会看到）；所以我们结合生产者 - 消费者模型，让主线程接收请求后把连接描述符放进缓存区，工作线程（worker thread）到缓冲区取描述符进行回复，以此让线程总数可控。

贴一小段主线程接收请求和工作线程的代码：

```cpp
  while (1) { 
    clientlen = sizeof(struct sockaddr_storage);
    connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen);
    sbuf_insert(&sbuf, connfd);                 // 插入缓存区，此处带锁
  }

  void *thread(void *vargp) {  
    Pthread_detach(pthread_self()); 
    while (1) { 
	int connfd = sbuf_remove(&sbuf);            // 从缓存区取出，此处带锁
	echo_cnt(connfd);                           // echo() 里加了记录总字节数，有意思
	Close(connfd);
    }
  }
```

echo_cnt() 的初始化，我们不用之前使用的，在主线程里显式调用初始化函数的方式，而是使用 pthread_once() 函数来演示一下另一种初始化方式：

```cpp
static int byte_cnt;                    // 存放总字节数的 static 变量
static sem_t mutex;

static void init_echo_cnt(void)         // 我们没有在主线程里调用它哟
{
    Sem_init(&mutex, 0, 1);
    byte_cnt = 0;
}

void echo_cnt(int connfd) 
{
    int n; 
    char buf[MAXLINE]; 
    rio_t rio;
    static pthread_once_t once = PTHREAD_ONCE_INIT;

    Pthread_once(&once, init_echo_cnt); // 保证了 init_echo_cnt 只会在第一次到这儿的时候被调用一次
    Rio_readinitb(&rio, connfd);
    while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) {
	P(&mutex);
	byte_cnt += n;
	printf("server received %d (%d total) bytes on fd %d\n", 
	       n, byte_cnt, connfd);
	V(&mutex);
	Rio_writen(connfd, buf, n);
    }
}
```

**利用线程来提高并行性**

---

关于并发和并行的关系，在开头我已经介绍过了。我们用一个求和 n 的例子，来考察怎么用线程利用好多核的并行。

总体思路，我们将 n 分为 t 块，创建 t 个线程，每个线程计算 n/t 个数字的和。细节的实现导致了性能的大不一样：

* 总是更新一个全局变量：用一个 gsum 全局变量来表示最终的求和值；每个线程依次将它要处理的数累加到 gsum 上，每次累加加互斥锁保证正确性。
* 总是更新一个全局数组：用一个 psum[t] 的全局数组来表示每个块的求和值，由主线程最后做一次累加；每个线程依次将它要处理的数累加到 psum[id] 上，这里没有共享的块不再需要加锁。
* 局部求和后更新全局数组：在线程中用局部变量先求和，然后放到 psum[id] 中。

从《CS: APP》给出的运行时长，我们可以看到以下现象：

* ① 很慢，并且增加线程数后反而更慢
  * 这是因为同步操作（P / V）的代价太大
* ②、③ 快多了，但是线程数超过核数后，速度减缓
  * 变快是因为没有同步操作，而线程数超过核数后，实际的计算能力没有长进，反而增加了调度开销
* ③ 比 ② 还要快不少
  * 这是因为引用局部变量带来的局部性优势，比频繁操作全局变量快很多

**其他并发问题**

---

* 线程安全（thread-safe）

我们称一个函数为线程安全的，当且仅当多个并发线程反复调用它时，总会产生正确的结果。

* 可重入性

一个可重入函数（reentrant function）被多个并发线程引用时，它不会引用任何共享变量。

* 竞争

当某线程的正确性，依赖于一个特定的并发逻辑流的执行顺序就引入了竞争；比如累加操作中，必须一个线程加完了，才能下一个加。

* 死锁

使用信号量时，某个线程被一个永远不可能为真的条件阻塞了，就导致了死锁（deadlock）。在二元信号量中，我们可以用一个简单的 FILO 的加锁、解锁顺序来保证没有死锁的出现。

小结

---

本章还是蛮有意思的，重点在于引入了并发的概念和并发编程的基本思路。诸如很多没有涉及到的内容才是实际使用中会用到的，比如多进程的 IPC，I/O multiplexing 里可以涉及的各种 I/O 模型，event-driven server 的设计，实际的多线程程序，多线程的各种玩儿法。但是本章里涉及到的思路可以说是比较 solid 的，并不是那种“过时”的内容，而实并发编程的核心思想。